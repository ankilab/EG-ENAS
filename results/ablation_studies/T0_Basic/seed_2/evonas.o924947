### Starting TaskPrologue of job 924947 on tg097 at Sun 03 Nov 2024 09:02:45 AM CET
Running on cores 0-31 with governor ondemand
Sun Nov  3 09:02:45 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:01:00.0 Off |                    0 |
| N/A   38C    P0             54W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

Loading python/pytorch-1.13py3.10
  Loading requirement: cuda/11.6.1
rm -Rf /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0
rm -Rf /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0
rm -Rf /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/predictions
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/datasets
rsync -ar --exclude='**/test_y.npy' datasets/* /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/datasets/
cp -R evaluation/main.py /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/main.py
cp -R anki_lab_submission/* /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0
cd /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0; python3 main.py --mode T0 --select_augment Basic
ic| self.select_augment: 'Basic'
ic| f"selected transform {train_transform}": ('selected transform [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, '
                                              '3.3), value=[0.0], inplace=False), RandomCrop(size=(24, 24), padding=[3, 3, '
                                              '3, 3], pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([50000, 1, 24, 24])
ic| self.x.shape: torch.Size([10000, 1, 24, 24])
ic| self.x.shape: torch.Size([10000, 1, 24, 24])
ic| mode: 'T0'
ic| 'No extended Regnet'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 42404610048
ic| self.total_generations: 3
ic| 'Time remaining:'
ic| metadata['time_remaining']: 107999.01292848587
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 10, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 1, 'STEM_W': 24, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                    score
                           xanthic_squid  83.840401
ic| best_models.keys(): dict_keys(['xanthic_squid'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 85.2,
               'codename': 'LaMelo',
               'input_shape': [50000, 1, 24, 24],
               'mode': 'NAS',
               'num_classes': 10,
               'test_type': 'T0_Basic/seed_2',
               'time_remaining': 107979.01502275467,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Basic'
ic| f"selected transform {train_transform}": ('selected transform [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, '
                                              '3.3), value=[0.0], inplace=False), RandomCrop(size=(27, 18), padding=[3, 3, '
                                              '2, 2], pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([45000, 1, 27, 18])
ic| self.x.shape: torch.Size([15000, 1, 27, 18])
ic| self.x.shape: torch.Size([6000, 1, 27, 18])
ic| mode: 'T0'
ic| 'No extended Regnet'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 36373135360
ic| self.total_generations: 3
ic| 'Time remaining:'
ic| metadata['time_remaining']: 105683.63373947144
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 6, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 1, 'STEM_W': 18, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                       score
                           mustard_capybara  97.457784
ic| best_models.keys(): dict_keys(['mustard_capybara'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 40.98,
               'codename': 'Gutenberg',
               'input_shape': [45000, 1, 27, 18],
               'mode': 'NAS',
               'num_classes': 6,
               'test_type': 'T0_Basic/seed_2',
               'time_remaining': 105664.59773683548,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Basic'
ic| f"selected transform {train_transform}": ('selected transform [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, '
                                              '3.3), value=[0.0], inplace=False), RandomCrop(size=(28, 28), padding=[3, 3, '
                                              '3, 3], pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([45000, 3, 28, 28])
ic| self.x.shape: torch.Size([15000, 3, 28, 28])
ic| self.x.shape: torch.Size([10000, 3, 28, 28])
ic| mode: 'T0'
ic| 'No extended Regnet'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 36064854016
ic| self.total_generations: 3
ic| 'Time remaining:'
ic| metadata['time_remaining']: 103221.16070747375
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 20, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 3, 'STEM_W': 28, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                   score
                           elite_gerbil  85.543301
ic| best_models.keys(): dict_keys(['elite_gerbil'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 89.85,
               'codename': 'Adaline',
               'input_shape': [50000, 3, 28, 28],
               'mode': 'NAS',
               'num_classes': 20,
               'test_type': 'T0_Basic/seed_2',
               'time_remaining': 103204.06497526169,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Basic'
ic| f"selected transform {train_transform}": ('selected transform [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, '
                                              '3.3), value=[0.0], inplace=False), RandomCrop(size=(8, 8), padding=[1, 1, 1, '
                                              '1], pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([49998, 12, 8, 8])
ic| self.x.shape: torch.Size([9999, 12, 8, 8])
ic| self.x.shape: torch.Size([9999, 12, 8, 8])
ic| mode: 'T0'
ic| 'No extended Regnet'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 35968385024
ic| self.total_generations: 3
ic| 'Time remaining:'
ic| metadata['time_remaining']: 101026.71992349625
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 3, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 12, 'STEM_W': 8, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                       score
                           enchanted_collie  97.123824
ic| best_models.keys(): dict_keys(['enchanted_collie'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 57.826,
               'codename': 'Chester',
               'input_shape': [49998, 12, 8, 8],
               'mode': 'NAS',
               'num_classes': 3,
               'test_type': 'T0_Basic/seed_2',
               'time_remaining': 101007.69598555565,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Basic'
ic| f"selected transform {train_transform}": ('selected transform [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, '
                                              '3.3), value=[0.0], inplace=False), RandomCrop(size=(64, 64), padding=[8, 8, '
                                              '8, 8], pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([43821, 3, 60, 60])
ic| self.x.shape: torch.Size([8785, 3, 60, 60])
ic| self.x.shape: torch.Size([8751, 3, 60, 60])
ic| mode: 'T0'
ic| 'No extended Regnet'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 35966287872
ic| self.total_generations: 3
ic| 'Time remaining:'
ic| metadata['time_remaining']: 99460.23972010612
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 10, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 3, 'STEM_W': 64, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                   score
                           quixotic_emu  83.994768
ic| best_models.keys(): dict_keys(['quixotic_emu'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 80.33,
               'codename': 'Sadie',
               'input_shape': [50000, 3, 64, 64],
               'mode': 'NAS',
               'num_classes': 10,
               'test_type': 'T0_Basic/seed_2',
               'time_remaining': 99442.51215267181,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Basic'
ic| f"selected transform {train_transform}": ('selected transform [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, '
                                              '3.3), value=[0.0], inplace=False), RandomCrop(size=(28, 28), padding=[3, 3, '
                                              '3, 3], pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([50000, 3, 28, 28])
ic| self.x.shape: torch.Size([10000, 3, 28, 28])
ic| self.x.shape: torch.Size([10000, 3, 28, 28])
ic| mode: 'T0'
ic| 'No extended Regnet'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 22991208448
ic| self.total_generations: 3
ic| 'Time remaining:'
ic| metadata['time_remaining']: 94714.48046827316
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 10, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 3, 'STEM_W': 28, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                  score
                           greedy_clam  90.192628
ic| best_models.keys(): dict_keys(['greedy_clam'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 90.87,
               'codename': 'Mateo',
               'input_shape': [50000, 3, 28, 28],
               'mode': 'NAS',
               'num_classes': 10,
               'test_type': 'T0_Basic/seed_2',
               'time_remaining': 94698.52832508087,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Basic'
ic| f"selected transform {train_transform}": ('selected transform [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, '
                                              '3.3), value=[0.0], inplace=False), RandomCrop(size=(64, 64), padding=[8, 8, '
                                              '8, 8], pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([45000, 3, 64, 64])
ic| self.x.shape: torch.Size([15000, 3, 64, 64])
ic| self.x.shape: torch.Size([10000, 3, 64, 64])
ic| mode: 'T0'
ic| 'No extended Regnet'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 22991208448
ic| self.total_generations: 3
ic| 'Time remaining:'
ic| metadata['time_remaining']: 92440.01532435417
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 4, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 3, 'STEM_W': 64, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                        score
                           saffron_dragonfly  78.748619
ic| best_models.keys(): dict_keys(['saffron_dragonfly'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 47.008,
               'codename': 'Caitie',
               'input_shape': [49260, 3, 64, 64],
               'mode': 'NAS',
               'num_classes': 4,
               'test_type': 'T0_Basic/seed_2',
               'time_remaining': 92423.2656698227,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
Mode: T0
===========================================================================
=============    Your Unseen Data 2024 Submission is running     =============
===========================================================================
========== Dataset   LaMelo   =============================================
  Metadata:
   - num_classes         : 10
   - codename            : LaMelo
   - input_shape         : [50000, 1, 24, 24]
   - benchmark           : 85.2
   - time_remaining      : 107999.83190989494

=== Processing Data ===
  Allotted compute time remaining: ~29h,59m,59s

=== Performing NAS ===
  Allotted compute time remaining: ~29h,59m,59s
None

=== Training ===
  Allotted compute time remaining: ~29h,59m,39s
Early stopping at epoch 88
[31m[EVAL] Best accuracy:79.97000122070312[0m

=== Predicting ===
  Allotted compute time remaining: ~29h,21m,25s

========== Dataset Gutenberg  =============================================
  Metadata:
   - input_shape         : [45000, 1, 27, 18]
   - codename            : Gutenberg
   - benchmark           : 40.98
   - num_classes         : 6
   - time_remaining      : 105683.70731925964

=== Processing Data ===
  Allotted compute time remaining: ~29h,21m,23s

=== Performing NAS ===
  Allotted compute time remaining: ~29h,21m,23s
spawn

=== Training ===
  Allotted compute time remaining: ~29h,21m,4s
[31m[EVAL] Best accuracy:46.11333465576172[0m

=== Predicting ===
  Allotted compute time remaining: ~28h,40m,23s

========== Dataset  Adaline   =============================================
  Metadata:
   - num_classes         : 20
   - input_shape         : [50000, 3, 28, 28]
   - codename            : Adaline
   - benchmark           : 89.85
   - time_remaining      : 103221.79392457008

=== Processing Data ===
  Allotted compute time remaining: ~28h,40m,21s

=== Performing NAS ===
  Allotted compute time remaining: ~28h,40m,21s
spawn

=== Training ===
  Allotted compute time remaining: ~28h,40m,4s
[31m[EVAL] Best accuracy:94.62000274658203[0m

=== Predicting ===
  Allotted compute time remaining: ~28h,3m,48s

========== Dataset  Chester   =============================================
  Metadata:
   - input_shape         : [49998, 12, 8, 8]
   - codename            : Chester
   - benchmark           : 57.826
   - num_classes         : 3
   - time_remaining      : 101026.86795949936

=== Processing Data ===
  Allotted compute time remaining: ~28h,3m,46s

=== Performing NAS ===
  Allotted compute time remaining: ~28h,3m,46s
spawn

=== Training ===
  Allotted compute time remaining: ~28h,3m,27s
Early stopping at epoch 55
[31m[EVAL] Best accuracy:60.40604019165039[0m

=== Predicting ===
  Allotted compute time remaining: ~27h,37m,50s

========== Dataset   Sadie    =============================================
  Metadata:
   - input_shape         : [50000, 3, 64, 64]
   - codename            : Sadie
   - benchmark           : 80.33
   - num_classes         : 10
   - time_remaining      : 99464.44942545891

=== Processing Data ===
  Allotted compute time remaining: ~27h,37m,44s

=== Performing NAS ===
  Allotted compute time remaining: ~27h,37m,40s
spawn

=== Training ===
  Allotted compute time remaining: ~27h,37m,22s
[31m[EVAL] Best accuracy:96.55094146728516[0m

=== Predicting ===
  Allotted compute time remaining: ~26h,18m,38s

========== Dataset   Mateo    =============================================
  Metadata:
   - num_classes         : 10
   - input_shape         : [50000, 3, 28, 28]
   - codename            : Mateo
   - benchmark           : 90.87
   - time_remaining      : 94715.18191027641

=== Processing Data ===
  Allotted compute time remaining: ~26h,18m,35s

=== Performing NAS ===
  Allotted compute time remaining: ~26h,18m,34s
spawn

=== Training ===
  Allotted compute time remaining: ~26h,18m,18s
[31m[EVAL] Best accuracy:97.6199951171875[0m

=== Predicting ===
  Allotted compute time remaining: ~25h,40m,49s

========== Dataset   Caitie   =============================================
  Metadata:
   - num_classes         : 4
   - input_shape         : [49260, 3, 64, 64]
   - codename            : Caitie
   - benchmark           : 47.008
   - time_remaining      : 92444.90745186806

=== Processing Data ===
  Allotted compute time remaining: ~25h,40m,44s

=== Performing NAS ===
  Allotted compute time remaining: ~25h,40m,40s
spawn

=== Training ===
  Allotted compute time remaining: ~25h,40m,23s
[31m[EVAL] Best accuracy:89.74666595458984[0m

=== Predicting ===
  Allotted compute time remaining: ~24h,29m,56s

rm -Rf /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0/labels
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0/predictions
rsync -avr --exclude='**/*x.npy' --exclude='**/train*.npy' --exclude='**/valid*.npy'   --include='**/test_y.npy' datasets/* /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0/labels/
sending incremental file list
AddNIST/
AddNIST/README
AddNIST/metadata
AddNIST/test_y.npy
CIFARTile/
CIFARTile/README.txt
CIFARTile/metadata
CIFARTile/test_y.npy
Chesseract/
Chesseract/README
Chesseract/metadata
Chesseract/test_y.npy
GeoClassing/
GeoClassing/README GeoClassing Dataset.txt
GeoClassing/metadata
GeoClassing/test_y.npy
Gutenberg/
Gutenberg/metadata
Gutenberg/test_y.npy
Language/
Language/README
Language/metadata
Language/test_y.npy
MultNIST/
MultNIST/README
MultNIST/metadata
MultNIST/test_y.npy

sent 529,436 bytes  received 448 bytes  1,059,768.00 bytes/sec
total size is 527,679  speedup is 1.00
cp -R /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/predictions /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0
cp evaluation/score.py /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0/score.py
cd /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0; python3 score.py
===========================================================================
=============    Your Unseen Data 2024 Submission is scoring     =============
===========================================================================
== Scoring Language ==
Raw Score:    79.660
Adj Score:    -3.743
Model Params: 20,976,270
Runtime:      2,315.8s
== Scoring Gutenberg ==
Raw Score:    46.800
Adj Score:    0.986
Model Params: 3,030,124
Runtime:      2,460.8s
== Scoring AddNIST ==
Raw Score:    95.550
Adj Score:    5.616
Model Params: 1,711,727
Runtime:      2,194.3s
== Scoring Chesseract ==
Raw Score:    59.096
Adj Score:    0.301
Model Params: 9,016,945
Runtime:      1,558.4s
== Scoring GeoClassing ==
Raw Score:    96.515
Adj Score:    8.228
Model Params: 9,288,916
Runtime:      4,748.5s
== Scoring MultNIST ==
Raw Score:    94.190
Adj Score:    3.636
Model Params: 1,022,959
Runtime:      2,266.3s
== Scoring CIFARTile ==
Raw Score:    81.860
Adj Score:    6.577
Model Params: 4,087,390
Runtime:      4,250.7s
===========================
Final Score: 21.601
=== JOB_STATISTICS ===
=== current date     : Sun 03 Nov 2024 02:34:08 PM CET
= Job-ID             : 924947 on tinygpu
= Job-Name           : /home/woody/iwb3/iwb3021h/THESIS_RESULTS/hpcruns/evonas
= Job-Command        : /home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/evonas_job_full_main_0.sh
= Initial workdir    : /home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024
= Queue/Partition    : a100
= Slurm account      : iwb3 with QOS=normal
= Requested resources:  for 23:59:00
= Elapsed runtime    : 05:31:41
= Total RAM usage    : 7.9 GiB of requested  GiB (%)   
= Node list          : tg097
= Subm/Elig/Start/End: 2024-11-03T09:02:26 / 2024-11-03T09:02:26 / 2024-11-03T09:02:27 / 2024-11-03T14:34:08
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc          103.9G   104.9G   209.7G        N/A     200K     500K   1,000K        N/A    
    /home/woody        963.1G  1000.0G  1500.0G        N/A     241K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:01:00.0, 1494732, 49 %, 29 %, 18508 MiB, 19810466 ms
