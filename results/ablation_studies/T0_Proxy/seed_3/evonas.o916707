### Starting TaskPrologue of job 916707 on tg092 at Wed 23 Oct 2024 07:22:06 AM CEST
Running on cores 96-127 with governor ondemand
Wed Oct 23 07:22:06 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:C1:00.0 Off |                    0 |
| N/A   32C    P0             52W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

Loading python/pytorch-1.13py3.10
  Loading requirement: cuda/11.6.1
rm -Rf /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0
rm -Rf /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0
rm -Rf /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/predictions
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/datasets
rsync -ar --exclude='**/test_y.npy' datasets/* /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/datasets/
cp -R evaluation/main.py /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/main.py
cp -R anki_lab_submission/* /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0
cd /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0; python3 main.py --mode T0 --select_augment Proxy
ic| self.select_augment: 'Proxy'
ic| self.x.shape: torch.Size([148700, 3, 16, 16])
ic| unique_values: array([0.02745098, 0.05098039, 0.05490196, 0.05882353, 0.0627451 ,
                          0.07058824, 0.07450981, 0.07843138, 0.08627451, 0.09019608,
                          0.09411765, 0.09803922, 0.10196079, 0.10980392, 0.11372549,
                          0.11764706, 0.12156863, 0.1254902 , 0.12941177, 0.13333334,
                          0.13725491, 0.14117648, 0.14509805, 0.14901961, 0.15294118,
                          0.15686275, 0.16078432, 0.16470589, 0.16862746, 0.17254902,
                          0.1764706 , 0.18039216, 0.18431373, 0.1882353 , 0.19215687,
                          0.19607843, 0.2       , 0.20392157, 0.21176471, 0.21568628,
                          0.21960784, 0.22352941, 0.22745098, 0.23137255, 0.23529412,
                          0.23921569, 0.24313726, 0.24705882, 0.2509804 , 0.25490198,
                          0.25882354, 0.2627451 , 0.26666668, 0.27058825, 0.27450982,
                          0.2784314 , 0.2901961 , 0.29411766, 0.29803923, 0.3019608 ,
                          0.3137255 , 0.31764707, 0.3254902 , 0.32941177, 0.33333334,
                          0.3372549 , 0.34117648, 0.34509805, 0.34901962, 0.3529412 ,
                          0.35686275, 0.36078432, 0.3647059 , 0.36862746, 0.37254903,
                          0.3764706 , 0.38039216, 0.38431373, 0.3882353 , 0.39215687,
                          0.39607844, 0.40392157, 0.40784314, 0.4117647 , 0.41568628,
                          0.41960785, 0.42352942, 0.43137255, 0.43529412, 0.4392157 ,
                          0.44313726, 0.44705883, 0.4509804 , 0.45490196, 0.45882353,
                          0.4627451 , 0.46666667, 0.47058824, 0.4745098 , 0.48235294,
                          0.4862745 , 0.49019608, 0.49411765, 0.49803922, 0.5019608 ,
                          0.5058824 , 0.50980395, 0.5137255 , 0.5176471 , 0.52156866,
                          0.5254902 , 0.5294118 , 0.53333336, 0.5372549 , 0.5411765 ,
                          0.54509807, 0.54901963, 0.5529412 , 0.5568628 , 0.56078434,
                          0.5647059 , 0.5686275 , 0.57254905, 0.5764706 , 0.5803922 ,
                          0.58431375, 0.5882353 , 0.5921569 , 0.59607846, 0.6       ,
                          0.6039216 , 0.60784316, 0.6117647 , 0.6156863 , 0.61960787,
                          0.62352943, 0.627451  , 0.6313726 , 0.63529414, 0.6392157 ,
                          0.6431373 , 0.64705884, 0.6509804 , 0.654902  , 0.65882355,
                          0.6627451 , 0.6666667 , 0.67058825, 0.6745098 , 0.6784314 ,
                          0.68235296, 0.6862745 , 0.6901961 , 0.69411767, 0.69803923,
                          0.7019608 , 0.7058824 , 0.70980394, 0.7137255 , 0.7176471 ,
                          0.72156864, 0.7254902 , 0.7294118 , 0.73333335, 0.7372549 ,
                          0.7411765 , 0.74509805, 0.7490196 , 0.7529412 , 0.75686276,
                          0.7607843 , 0.7647059 , 0.76862746, 0.77254903, 0.7764706 ,
                          0.78039217, 0.78431374, 0.7882353 , 0.7921569 , 0.79607844,
                          0.8       , 0.8039216 , 0.80784315, 0.8117647 , 0.8156863 ,
                          0.8235294 , 0.83137256, 0.8352941 , 0.8392157 , 0.84313726,
                          0.85882354, 0.8666667 , 0.87058824, 0.8745098 , 0.8784314 ,
                          0.88235295, 0.8980392 , 0.90588236, 0.9098039 , 0.9137255 ,
                          0.91764706, 0.92156863, 0.9254902 , 0.92941177, 0.93333334,
                          0.9372549 , 0.9411765 , 0.94509804, 0.95686275, 0.9607843 ],
                         dtype=float32)
ic| C: 3
ic| H: 16
ic| PH: 2
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.
  warnings.warn(
ic| poss_augs: [[],
                [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=9, num_magnitude_bins=31)],
                [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=5, num_magnitude_bins=31)],
                [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=1, num_magnitude_bins=31)],
                [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=31)],
                [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=15)],
                [AugMix(interpolation=InterpolationMode.BILINEAR, severity=3, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True)],
                [AugMix(interpolation=InterpolationMode.BILINEAR, severity=1, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True)],
                [RandomHorizontalFlip(p=0.5), RandomVerticalFlip(p=0.5)],
                [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5)],
                [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False)],
                [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                 RandomCrop(size=(16, 16), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant)],
                [RandomCrop(size=(16, 16), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant)],
                [RandomCrop(size=(16, 16), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5)],
                [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                 RandomCrop(size=(16, 16), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant),
                 RandomHorizontalFlip(p=0.5)],
                [<data_processor.RandomPixelChange object at 0x7f1310cf3ee0>, ToTensor()],
                [<data_processor.RandomPixelChange object at 0x7f1310cf3fa0>, ToTensor()],
                [<data_processor.RandomPixelChange object at 0x7f1310cf0f70>, ToTensor()],
                [<data_processor.RandomPixelChange object at 0x7f1310cf3fd0>,
                 ToTensor(),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5)],
                [<data_processor.RandomPixelChange object at 0x7f1310cf1090>,
                 ToTensor(),
                 RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False)],
                [<data_processor.RandomPixelChange object at 0x7f1310cf1840>,
                 ToTensor(),
                 RandomCrop(size=(16, 16), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant)],
                [<data_processor.RandomPixelChange object at 0x7f1310cf12a0>,
                 ToTensor(),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5),
                 RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False)]]
ic| individuals: ['devious_fossa',
                  'xanthic_ara',
                  'poised_dachshund',
                  'bronze_angelfish',
                  'russet_orca',
                  'gay_mink',
                  'sensible_dragon',
                  'enchanted_cockatoo',
                  'remarkable_jaguar',
                  'omniscient_chachalaca',
                  'ruby_turaco',
                  'astonishing_hedgehog',
                  'wisteria_dolphin',
                  'quartz_rat',
                  'carrot_hawk',
                  'foamy_uakari',
                  'roaring_coucal',
                  'clay_bulldog',
                  'bouncy_coyote',
                  'imported_galago']
ic| params: [48.0, 80, 2.249999999999999, 13, 8]
ic| params: [16.0, 88, 2.05, 22, 8]
ic| params: [48.0, 112, 2.3499999999999988, 19, 8]
ic| params: [40.0, 64, 2.249999999999999, 11, 8]
ic| params: [40.0, 104, 2.05, 18, 8]
ic| params: [64.0, 88, 2.0999999999999996, 12, 8]
ic| params: [40.0, 88, 2.6499999999999977, 19, 8]
ic| params: [56.0, 112, 2.7499999999999973, 22, 8]
ic| params: [16.0, 16, 2.249999999999999, 15, 8]
ic| params: [56.0, 64, 2.4999999999999982, 14, 8]
ic| params: [32.0, 80, 2.6999999999999975, 17, 8]
ic| params: [56.0, 96, 2.4499999999999984, 17, 8]
ic| params: [48.0, 88, 2.1999999999999993, 19, 8]
ic| params: [32.0, 48, 2.1999999999999993, 9, 8]
ic| params: [16.0, 56, 2.1499999999999995, 14, 8]
ic| params: [32.0, 64, 2.6999999999999975, 21, 8]
ic| params: [48.0, 88, 2.0999999999999996, 14, 8]
ic| params: [32.0, 80, 2.3999999999999986, 8, 8]
ic| params: [16.0, 24, 2.899999999999997, 8, 8]
ic| params: [32.0, 88, 2.4499999999999984, 10, 8]
ic| individuals: ['devious_fossa',
                  'xanthic_ara',
                  'poised_dachshund',
                  'bronze_angelfish',
                  'russet_orca',
                  'gay_mink',
                  'sensible_dragon',
                  'enchanted_cockatoo',
                  'remarkable_jaguar',
                  'omniscient_chachalaca',
                  'ruby_turaco',
                  'astonishing_hedgehog',
                  'wisteria_dolphin',
                  'quartz_rat',
                  'carrot_hawk',
                  'foamy_uakari',
                  'roaring_coucal',
                  'clay_bulldog',
                  'bouncy_coyote',
                  'imported_galago']
ic| params_dict: {'astonishing_hedgehog': [56.0, 96, 2.4499999999999984, 17, 8],
                  'bouncy_coyote': [16.0, 24, 2.899999999999997, 8, 8],
                  'bronze_angelfish': [40.0, 64, 2.249999999999999, 11, 8],
                  'carrot_hawk': [16.0, 56, 2.1499999999999995, 14, 8],
                  'clay_bulldog': [32.0, 80, 2.3999999999999986, 8, 8],
                  'devious_fossa': [48.0, 80, 2.249999999999999, 13, 8],
                  'enchanted_cockatoo': [56.0, 112, 2.7499999999999973, 22, 8],
                  'foamy_uakari': [32.0, 64, 2.6999999999999975, 21, 8],
                  'gay_mink': [64.0, 88, 2.0999999999999996, 12, 8],
                  'imported_galago': [32.0, 88, 2.4499999999999984, 10, 8],
                  'omniscient_chachalaca': [56.0, 64, 2.4999999999999982, 14, 8],
                  'poised_dachshund': [48.0, 112, 2.3499999999999988, 19, 8],
                  'quartz_rat': [32.0, 48, 2.1999999999999993, 9, 8],
                  'remarkable_jaguar': [16.0, 16, 2.249999999999999, 15, 8],
                  'roaring_coucal': [48.0, 88, 2.0999999999999996, 14, 8],
                  'ruby_turaco': [32.0, 80, 2.6999999999999975, 17, 8],
                  'russet_orca': [40.0, 104, 2.05, 18, 8],
                  'sensible_dragon': [40.0, 88, 2.6499999999999977, 19, 8],
                  'wisteria_dolphin': [48.0, 88, 2.1999999999999993, 19, 8],
                  'xanthic_ara': [16.0, 88, 2.05, 22, 8]}
ic| '#############'
ic| aug: 0
ic| train_loader.dataset.transform.transforms: [Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 1
ic| train_loader.dataset.transform.transforms: [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=9, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 2
ic| train_loader.dataset.transform.transforms: [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=5, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 3
ic| train_loader.dataset.transform.transforms: [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=1, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 4
ic| train_loader.dataset.transform.transforms: [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 5
ic| train_loader.dataset.transform.transforms: [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=15),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 6
ic| train_loader.dataset.transform.transforms: [AugMix(interpolation=InterpolationMode.BILINEAR, severity=3, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 7
ic| train_loader.dataset.transform.transforms: [AugMix(interpolation=InterpolationMode.BILINEAR, severity=1, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 8
ic| train_loader.dataset.transform.transforms: [RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 9
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 10
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 11
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                RandomCrop(size=(16, 16), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 12
ic| train_loader.dataset.transform.transforms: [RandomCrop(size=(16, 16), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 13
ic| train_loader.dataset.transform.transforms: [RandomCrop(size=(16, 16), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 14
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                RandomCrop(size=(16, 16), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant),
                                                RandomHorizontalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 15
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1310cf3ee0>,
                                                ToTensor(),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 16
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1310cf3fa0>,
                                                ToTensor(),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 17
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1310cf0f70>,
                                                ToTensor(),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 18
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1310cf3fd0>,
                                                ToTensor(),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 19
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1310cf1090>,
                                                ToTensor(),
                                                RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 20
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1310cf1840>,
                                                ToTensor(),
                                                RandomCrop(size=(16, 16), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 21
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1310cf12a0>,
                                                ToTensor(),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                Normalize(mean=tensor([0.4712, 0.4543, 0.3944]), std=tensor([0.2319, 0.2252, 0.2321]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:590: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["fisher"] = scaler.fit_transform(subset_df_no_outliers[["fisher"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:590: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["fisher"] = scaler.fit_transform(subset_df_no_outliers[["fisher"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:608: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["jacob_cov"] = scaler.fit_transform(subset_df_no_outliers[["jacob_cov"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:608: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["jacob_cov"] = scaler.fit_transform(subset_df_no_outliers[["jacob_cov"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:608: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["jacob_cov"] = scaler.fit_transform(subset_df_no_outliers[["jacob_cov"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:608: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["jacob_cov"] = scaler.fit_transform(subset_df_no_outliers[["jacob_cov"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:608: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["jacob_cov"] = scaler.fit_transform(subset_df_no_outliers[["jacob_cov"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:608: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["jacob_cov"] = scaler.fit_transform(subset_df_no_outliers[["jacob_cov"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:608: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["jacob_cov"] = scaler.fit_transform(subset_df_no_outliers[["jacob_cov"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:608: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["jacob_cov"] = scaler.fit_transform(subset_df_no_outliers[["jacob_cov"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:608: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["jacob_cov"] = scaler.fit_transform(subset_df_no_outliers[["jacob_cov"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:608: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["jacob_cov"] = scaler.fit_transform(subset_df_no_outliers[["jacob_cov"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:608: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["jacob_cov"] = scaler.fit_transform(subset_df_no_outliers[["jacob_cov"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:608: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["jacob_cov"] = scaler.fit_transform(subset_df_no_outliers[["jacob_cov"]])
ic| f"best_augmentation: {best_aug}": 'best_augmentation: 5'
ic| f"selected transform {train_transform}": ('selected transform '
                                              '[TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, '
                                              'num_magnitude_bins=15)]')
ic| self.x.shape: torch.Size([148700, 3, 16, 16])
ic| self.x.shape: torch.Size([3000, 3, 16, 16])
ic| self.x.shape: torch.Size([3000, 3, 16, 16])
ic| mode: 'T0'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 41727164416
ic| self.total_generations: 3
ic| 'Time remaining:'
ic| metadata['time_remaining']: 107420.12473464012
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 120, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 3, 'STEM_W': 16, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SGDRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                       score
                           thankful_turkey  180.069942
ic| best_models.keys(): dict_keys(['thankful_turkey'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 46.38,
               'codename': 'in16',
               'input_shape': [148700, 3, 16, 16],
               'mode': 'NAS',
               'num_classes': 120,
               'test_type': 'T0_Proxy/seed_3',
               'time_remaining': 107401.30984663963,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Proxy'
ic| self.x.shape: torch.Size([50000, 20, 20, 20])
ic| unique_values: array([0., 1.], dtype=float32)
ic| C: 20
ic| H: 20
ic| PH: 2
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.
  warnings.warn(
ic| poss_augs: [[],
                [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=9, num_magnitude_bins=31)],
                [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=5, num_magnitude_bins=31)],
                [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=1, num_magnitude_bins=31)],
                [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=31)],
                [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=15)],
                [AugMix(interpolation=InterpolationMode.BILINEAR, severity=3, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True)],
                [AugMix(interpolation=InterpolationMode.BILINEAR, severity=1, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True)],
                [RandomHorizontalFlip(p=0.5), RandomVerticalFlip(p=0.5)],
                [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5)],
                [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False)],
                [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                 RandomCrop(size=(20, 20), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant)],
                [RandomCrop(size=(20, 20), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant)],
                [RandomCrop(size=(20, 20), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5)],
                [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                 RandomCrop(size=(20, 20), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant),
                 RandomHorizontalFlip(p=0.5)],
                [<data_processor.RandomPixelChange object at 0x7f124abce200>, ToTensor()],
                [<data_processor.RandomPixelChange object at 0x7f124abcf940>, ToTensor()],
                [<data_processor.RandomPixelChange object at 0x7f124abcc610>, ToTensor()],
                [<data_processor.RandomPixelChange object at 0x7f12bde6a4d0>,
                 ToTensor(),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5)],
                [<data_processor.RandomPixelChange object at 0x7f1296334700>,
                 ToTensor(),
                 RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False)],
                [<data_processor.RandomPixelChange object at 0x7f124ace9cf0>,
                 ToTensor(),
                 RandomCrop(size=(20, 20), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant)],
                [<data_processor.RandomPixelChange object at 0x7f124ace9000>,
                 ToTensor(),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5),
                 RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False)]]
ic| individuals: ['smart_dog',
                  'lime_termite',
                  'interesting_tortoise',
                  'sexy_crab',
                  'jasmine_pheasant',
                  'sly_oarfish',
                  'imposing_cricket',
                  'energetic_seagull',
                  'asparagus_elephant',
                  'cornflower_dragon',
                  'tested_rattlesnake',
                  'innocent_boa',
                  'festive_mouflon',
                  'hilarious_lizard',
                  'nano_snake',
                  'wandering_booby',
                  'attractive_skua',
                  'tactful_quail',
                  'dynamic_coot',
                  'zippy_pelican']
ic| params: [64.0, 72, 2.4999999999999982, 15, 8]
ic| params: [32.0, 72, 2.549999999999998, 18, 8]
ic| params: [16.0, 96, 2.6999999999999975, 9, 8]
ic| params: [16.0, 96, 2.1499999999999995, 8, 8]
ic| params: [16.0, 72, 2.0999999999999996, 11, 8]
ic| params: [64.0, 72, 2.549999999999998, 20, 8]
ic| params: [56.0, 64, 2.6499999999999977, 12, 8]
ic| params: [24.0, 120, 2.6999999999999975, 9, 8]
ic| params: [32.0, 80, 2.6499999999999977, 10, 8]
ic| params: [32.0, 32, 2.599999999999998, 20, 8]
ic| params: [24.0, 72, 2.799999999999997, 13, 8]
ic| params: [48.0, 104, 2.6499999999999977, 15, 8]
ic| params: [24.0, 104, 2.05, 21, 8]
ic| params: [64.0, 104, 2.1999999999999993, 13, 8]
ic| params: [64.0, 112, 2.0999999999999996, 22, 8]
ic| params: [40.0, 120, 2.549999999999998, 13, 8]
ic| params: [24.0, 64, 2.1999999999999993, 13, 8]
ic| params: [40.0, 56, 2.3499999999999988, 11, 8]
ic| params: [48.0, 72, 2.1999999999999993, 11, 8]
ic| params: [64.0, 80, 2.849999999999997, 14, 8]
ic| individuals: ['smart_dog',
                  'lime_termite',
                  'interesting_tortoise',
                  'sexy_crab',
                  'jasmine_pheasant',
                  'sly_oarfish',
                  'imposing_cricket',
                  'energetic_seagull',
                  'asparagus_elephant',
                  'cornflower_dragon',
                  'tested_rattlesnake',
                  'innocent_boa',
                  'festive_mouflon',
                  'hilarious_lizard',
                  'nano_snake',
                  'wandering_booby',
                  'attractive_skua',
                  'tactful_quail',
                  'dynamic_coot',
                  'zippy_pelican']
ic| params_dict: {'asparagus_elephant': [32.0, 80, 2.6499999999999977, 10, 8],
                  'attractive_skua': [24.0, 64, 2.1999999999999993, 13, 8],
                  'cornflower_dragon': [32.0, 32, 2.599999999999998, 20, 8],
                  'dynamic_coot': [48.0, 72, 2.1999999999999993, 11, 8],
                  'energetic_seagull': [24.0, 120, 2.6999999999999975, 9, 8],
                  'festive_mouflon': [24.0, 104, 2.05, 21, 8],
                  'hilarious_lizard': [64.0, 104, 2.1999999999999993, 13, 8],
                  'imposing_cricket': [56.0, 64, 2.6499999999999977, 12, 8],
                  'innocent_boa': [48.0, 104, 2.6499999999999977, 15, 8],
                  'interesting_tortoise': [16.0, 96, 2.6999999999999975, 9, 8],
                  'jasmine_pheasant': [16.0, 72, 2.0999999999999996, 11, 8],
                  'lime_termite': [32.0, 72, 2.549999999999998, 18, 8],
                  'nano_snake': [64.0, 112, 2.0999999999999996, 22, 8],
                  'sexy_crab': [16.0, 96, 2.1499999999999995, 8, 8],
                  'sly_oarfish': [64.0, 72, 2.549999999999998, 20, 8],
                  'smart_dog': [64.0, 72, 2.4999999999999982, 15, 8],
                  'tactful_quail': [40.0, 56, 2.3499999999999988, 11, 8],
                  'tested_rattlesnake': [24.0, 72, 2.799999999999997, 13, 8],
                  'wandering_booby': [40.0, 120, 2.549999999999998, 13, 8],
                  'zippy_pelican': [64.0, 80, 2.849999999999997, 14, 8]}
ic| '#############'
ic| aug: 0
ic| train_loader.dataset.transform.transforms: [Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 1
ic| train_loader.dataset.transform.transforms: [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=9, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
ic| '#############'
ic| aug: 2
ic| train_loader.dataset.transform.transforms: [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=5, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
ic| '#############'
ic| aug: 3
ic| train_loader.dataset.transform.transforms: [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=1, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
ic| '#############'
ic| aug: 4
ic| train_loader.dataset.transform.transforms: [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
ic| '#############'
ic| aug: 5
ic| train_loader.dataset.transform.transforms: [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=15),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
ic| '#############'
ic| aug: 6
ic| train_loader.dataset.transform.transforms: [AugMix(interpolation=InterpolationMode.BILINEAR, severity=3, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
ic| '#############'
ic| aug: 7
ic| train_loader.dataset.transform.transforms: [AugMix(interpolation=InterpolationMode.BILINEAR, severity=1, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
ic| '#############'
ic| aug: 8
ic| train_loader.dataset.transform.transforms: [RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 9
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 10
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 11
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                RandomCrop(size=(20, 20), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 12
ic| train_loader.dataset.transform.transforms: [RandomCrop(size=(20, 20), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 13
ic| train_loader.dataset.transform.transforms: [RandomCrop(size=(20, 20), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 14
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                RandomCrop(size=(20, 20), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant),
                                                RandomHorizontalFlip(p=0.5),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 15
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f124abce200>,
                                                ToTensor(),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 16
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f124abcf940>,
                                                ToTensor(),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 17
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f124abcc610>,
                                                ToTensor(),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 18
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f12bde6a4d0>,
                                                ToTensor(),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 19
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1296334700>,
                                                ToTensor(),
                                                RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 20
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f124ace9cf0>,
                                                ToTensor(),
                                                RandomCrop(size=(20, 20), padding=[2, 2, 2, 2], pad_if_needed=False, fill=0, padding_mode=constant),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 21
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f124ace9000>,
                                                ToTensor(),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                Normalize(mean=tensor([0.0724, 0.0832, 0.0932, 0.1020, 0.1097, 0.1162, 0.1213, 0.1250, 0.1275,
                                                       0.1288, 0.1289, 0.1274, 0.1250, 0.1211, 0.1157, 0.1091, 0.1012, 0.0924,
                                                       0.0824, 0.0716]), std=tensor([0.2592, 0.2762, 0.2907, 0.3026, 0.3125, 0.3204, 0.3264, 0.3307, 0.3336,
                                                       0.3350, 0.3351, 0.3334, 0.3308, 0.3263, 0.3198, 0.3117, 0.3016, 0.2896,
                                                       0.2750, 0.2578]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| f"best_augmentation: {best_aug}": 'best_augmentation: 13'
ic| f"selected transform {train_transform}": ('selected transform [RandomCrop(size=(20, 20), padding=[2, 2, 2, 2], '
                                              'pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5), RandomVerticalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([50000, 20, 20, 20])
ic| self.x.shape: torch.Size([10000, 20, 20, 20])
ic| self.x.shape: torch.Size([10000, 20, 20, 20])
ic| mode: 'T0'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 41230139392
ic| self.total_generations: 3
ic| 'Time remaining:'
ic| metadata['time_remaining']: 103754.71317577362
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 7, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 20, 'STEM_W': 20, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SGDRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                       score
                           piquant_gharial  180.099606
ic| best_models.keys(): dict_keys(['piquant_gharial'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 71.35,
               'codename': 'Volga',
               'input_shape': [50000, 20, 20, 20],
               'mode': 'NAS',
               'num_classes': 7,
               'test_type': 'T0_Proxy/seed_3',
               'time_remaining': 103741.01300597191,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Proxy'
ic| self.x.shape: torch.Size([50000, 1, 9, 9])
ic| unique_values: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ],
                         dtype=float32)
ic| C: 1
ic| H: 9
ic| PH: 1
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.
  warnings.warn(
ic| poss_augs: [[],
                [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=9, num_magnitude_bins=31)],
                [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=5, num_magnitude_bins=31)],
                [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=1, num_magnitude_bins=31)],
                [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=31)],
                [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=15)],
                [AugMix(interpolation=InterpolationMode.BILINEAR, severity=3, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True)],
                [AugMix(interpolation=InterpolationMode.BILINEAR, severity=1, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True)],
                [RandomHorizontalFlip(p=0.5), RandomVerticalFlip(p=0.5)],
                [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5)],
                [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False)],
                [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                 RandomCrop(size=(9, 9), padding=[1, 1, 1, 1], pad_if_needed=False, fill=0, padding_mode=constant)],
                [RandomCrop(size=(9, 9), padding=[1, 1, 1, 1], pad_if_needed=False, fill=0, padding_mode=constant)],
                [RandomCrop(size=(9, 9), padding=[1, 1, 1, 1], pad_if_needed=False, fill=0, padding_mode=constant),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5)],
                [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                 RandomCrop(size=(9, 9), padding=[1, 1, 1, 1], pad_if_needed=False, fill=0, padding_mode=constant),
                 RandomHorizontalFlip(p=0.5)],
                [<data_processor.RandomPixelChange object at 0x7f1250316800>, ToTensor()],
                [<data_processor.RandomPixelChange object at 0x7f12503144f0>, ToTensor()],
                [<data_processor.RandomPixelChange object at 0x7f1250314eb0>, ToTensor()],
                [<data_processor.RandomPixelChange object at 0x7f1250315cc0>,
                 ToTensor(),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5)],
                [<data_processor.RandomPixelChange object at 0x7f1304d44e20>,
                 ToTensor(),
                 RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False)],
                [<data_processor.RandomPixelChange object at 0x7f1300c16770>,
                 ToTensor(),
                 RandomCrop(size=(9, 9), padding=[1, 1, 1, 1], pad_if_needed=False, fill=0, padding_mode=constant)],
                [<data_processor.RandomPixelChange object at 0x7f1310354610>,
                 ToTensor(),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5),
                 RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False)]]
ic| individuals: ['flying_flounder',
                  'wine_bullfrog',
                  'cornflower_potoo',
                  'ninja_lori',
                  'annoying_crayfish',
                  'granite_bumblebee',
                  'blond_salamander',
                  'aloof_quoll',
                  'enigmatic_trout',
                  'analytic_dragon',
                  'sociable_smilodon',
                  'brainy_anteater',
                  'hopeful_panther',
                  'outstanding_quokka',
                  'rare_tuatara',
                  'festive_caterpillar',
                  'truthful_muskox',
                  'outstanding_sponge',
                  'ambitious_meerkat',
                  'active_walrus']
ic| params: [48.0, 64, 2.549999999999998, 22, 8]
ic| params: [40.0, 72, 2.3499999999999988, 22, 8]
ic| params: [48.0, 56, 2.1999999999999993, 19, 8]
ic| params: [40.0, 104, 2.3499999999999988, 10, 8]
ic| params: [16.0, 80, 2.899999999999997, 9, 8]
ic| params: [48.0, 56, 2.6499999999999977, 12, 8]
ic| params: [32.0, 96, 2.549999999999998, 11, 8]
ic| params: [24.0, 24, 2.799999999999997, 13, 8]
ic| params: [32.0, 56, 2.299999999999999, 12, 8]
ic| params: [24.0, 48, 2.599999999999998, 19, 8]
ic| params: [16.0, 120, 2.249999999999999, 20, 8]
ic| params: [40.0, 56, 2.1999999999999993, 13, 8]
ic| params: [16.0, 96, 2.799999999999997, 12, 8]
ic| params: [64.0, 72, 2.6999999999999975, 16, 8]
ic| params: [32.0, 48, 2.899999999999997, 12, 8]
ic| params: [16.0, 16, 2.299999999999999, 14, 8]
ic| params: [64.0, 112, 2.249999999999999, 16, 8]
ic| params: [32.0, 56, 2.899999999999997, 17, 8]
ic| params: [24.0, 40, 2.1499999999999995, 15, 8]
ic| params: [24.0, 24, 2.899999999999997, 13, 8]
ic| individuals: ['flying_flounder',
                  'wine_bullfrog',
                  'cornflower_potoo',
                  'ninja_lori',
                  'annoying_crayfish',
                  'granite_bumblebee',
                  'blond_salamander',
                  'aloof_quoll',
                  'enigmatic_trout',
                  'analytic_dragon',
                  'sociable_smilodon',
                  'brainy_anteater',
                  'hopeful_panther',
                  'outstanding_quokka',
                  'rare_tuatara',
                  'festive_caterpillar',
                  'truthful_muskox',
                  'outstanding_sponge',
                  'ambitious_meerkat',
                  'active_walrus']
ic| params_dict: {'active_walrus': [24.0, 24, 2.899999999999997, 13, 8],
                  'aloof_quoll': [24.0, 24, 2.799999999999997, 13, 8],
                  'ambitious_meerkat': [24.0, 40, 2.1499999999999995, 15, 8],
                  'analytic_dragon': [24.0, 48, 2.599999999999998, 19, 8],
                  'annoying_crayfish': [16.0, 80, 2.899999999999997, 9, 8],
                  'blond_salamander': [32.0, 96, 2.549999999999998, 11, 8],
                  'brainy_anteater': [40.0, 56, 2.1999999999999993, 13, 8],
                  'cornflower_potoo': [48.0, 56, 2.1999999999999993, 19, 8],
                  'enigmatic_trout': [32.0, 56, 2.299999999999999, 12, 8],
                  'festive_caterpillar': [16.0, 16, 2.299999999999999, 14, 8],
                  'flying_flounder': [48.0, 64, 2.549999999999998, 22, 8],
                  'granite_bumblebee': [48.0, 56, 2.6499999999999977, 12, 8],
                  'hopeful_panther': [16.0, 96, 2.799999999999997, 12, 8],
                  'ninja_lori': [40.0, 104, 2.3499999999999988, 10, 8],
                  'outstanding_quokka': [64.0, 72, 2.6999999999999975, 16, 8],
                  'outstanding_sponge': [32.0, 56, 2.899999999999997, 17, 8],
                  'rare_tuatara': [32.0, 48, 2.899999999999997, 12, 8],
                  'sociable_smilodon': [16.0, 120, 2.249999999999999, 20, 8],
                  'truthful_muskox': [64.0, 112, 2.249999999999999, 16, 8],
                  'wine_bullfrog': [40.0, 72, 2.3499999999999988, 22, 8]}
ic| '#############'
ic| aug: 0
ic| train_loader.dataset.transform.transforms: [Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 1
ic| train_loader.dataset.transform.transforms: [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=9, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 2
ic| train_loader.dataset.transform.transforms: [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=5, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 3
ic| train_loader.dataset.transform.transforms: [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=1, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 4
ic| train_loader.dataset.transform.transforms: [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 5
ic| train_loader.dataset.transform.transforms: [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=15),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 6
ic| train_loader.dataset.transform.transforms: [AugMix(interpolation=InterpolationMode.BILINEAR, severity=3, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 7
ic| train_loader.dataset.transform.transforms: [AugMix(interpolation=InterpolationMode.BILINEAR, severity=1, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 8
ic| train_loader.dataset.transform.transforms: [RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 9
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 10
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 11
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                RandomCrop(size=(9, 9), padding=[1, 1, 1, 1], pad_if_needed=False, fill=0, padding_mode=constant),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 12
ic| train_loader.dataset.transform.transforms: [RandomCrop(size=(9, 9), padding=[1, 1, 1, 1], pad_if_needed=False, fill=0, padding_mode=constant),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 13
ic| train_loader.dataset.transform.transforms: [RandomCrop(size=(9, 9), padding=[1, 1, 1, 1], pad_if_needed=False, fill=0, padding_mode=constant),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 14
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                RandomCrop(size=(9, 9), padding=[1, 1, 1, 1], pad_if_needed=False, fill=0, padding_mode=constant),
                                                RandomHorizontalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 15
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1250316800>,
                                                ToTensor(),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 16
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f12503144f0>,
                                                ToTensor(),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 17
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1250314eb0>,
                                                ToTensor(),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 18
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1250315cc0>,
                                                ToTensor(),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 19
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1304d44e20>,
                                                ToTensor(),
                                                RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 20
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1300c16770>,
                                                ToTensor(),
                                                RandomCrop(size=(9, 9), padding=[1, 1, 1, 1], pad_if_needed=False, fill=0, padding_mode=constant),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 21
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1310354610>,
                                                ToTensor(),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                Normalize(mean=tensor([0.4198]), std=tensor([0.3068]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: ComplexWarning: Casting complex values to real discards the imaginary part
  return arr.astype(dtype, copy=True)
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: ComplexWarning: Casting complex values to real discards the imaginary part
  return arr.astype(dtype, copy=True)
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:590: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["fisher"] = scaler.fit_transform(subset_df_no_outliers[["fisher"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:590: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["fisher"] = scaler.fit_transform(subset_df_no_outliers[["fisher"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:590: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["fisher"] = scaler.fit_transform(subset_df_no_outliers[["fisher"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:590: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["fisher"] = scaler.fit_transform(subset_df_no_outliers[["fisher"]])
ic| f"best_augmentation: {best_aug}": 'best_augmentation: 1'
ic| f"selected transform {train_transform}": ('selected transform [RandAugment(interpolation=InterpolationMode.NEAREST, '
                                              'num_ops=2, magnitude=9, num_magnitude_bins=31)]')
ic| self.x.shape: torch.Size([50000, 1, 9, 9])
ic| self.x.shape: torch.Size([10000, 1, 9, 9])
ic| self.x.shape: torch.Size([10000, 1, 9, 9])
ic| mode: 'T0'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 41752330240
ic| self.total_generations: 3
ic| 'Time remaining:'
ic| metadata['time_remaining']: 101111.72211909294
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 9, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 1, 'STEM_W': 9, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SGDRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                         score
                           succinct_antelope  185.985707
ic| best_models.keys(): dict_keys(['succinct_antelope'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 0.0,
               'codename': 'Sokoto',
               'input_shape': [50000, 1, 9, 9],
               'mode': 'NAS',
               'num_classes': 9,
               'test_type': 'T0_Proxy/seed_3',
               'time_remaining': 101094.52310609818,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Proxy'
ic| self.x.shape: torch.Size([40000, 3, 32, 32])
ic| unique_values: array([0.09411765, 0.09803922, 0.10196079, 0.10588235, 0.10980392,
                          0.11372549, 0.11764706, 0.12156863, 0.1254902 , 0.12941177,
                          0.13333334, 0.13725491, 0.14117648, 0.14509805, 0.14901961,
                          0.15294118, 0.15686275, 0.16078432, 0.16470589, 0.16862746,
                          0.17254902, 0.1764706 , 0.18039216, 0.18431373, 0.1882353 ,
                          0.19215687, 0.19607843, 0.2       , 0.20392157, 0.20784314,
                          0.21176471, 0.21568628, 0.21960784, 0.22352941, 0.22745098,
                          0.23137255, 0.23529412, 0.23921569, 0.24313726, 0.24705882,
                          0.2509804 , 0.25490198, 0.25882354, 0.2627451 , 0.26666668,
                          0.27058825, 0.27450982, 0.2784314 , 0.28235295, 0.28627452,
                          0.2901961 , 0.29411766, 0.29803923, 0.3019608 , 0.30588236,
                          0.30980393, 0.3137255 , 0.31764707, 0.32156864, 0.3254902 ,
                          0.32941177, 0.33333334, 0.3372549 , 0.34117648, 0.34509805,
                          0.34901962, 0.3529412 , 0.35686275, 0.36078432, 0.3647059 ,
                          0.36862746, 0.37254903, 0.3764706 , 0.38039216, 0.38431373,
                          0.3882353 , 0.39215687, 0.39607844, 0.4       , 0.40392157,
                          0.40784314, 0.4117647 , 0.41568628, 0.41960785, 0.42352942,
                          0.42745098, 0.43137255, 0.43529412, 0.4392157 , 0.44313726,
                          0.44705883, 0.4509804 , 0.45490196, 0.45882353, 0.4627451 ,
                          0.46666667, 0.47058824, 0.4745098 , 0.47843137, 0.48235294,
                          0.4862745 , 0.49019608, 0.49411765, 0.49803922, 0.5019608 ,
                          0.5058824 , 0.50980395, 0.5137255 , 0.5176471 , 0.52156866,
                          0.5254902 , 0.5294118 , 0.53333336, 0.5372549 , 0.5411765 ,
                          0.54509807, 0.54901963, 0.5529412 , 0.5568628 , 0.56078434,
                          0.5647059 , 0.5686275 , 0.57254905, 0.5764706 , 0.5803922 ,
                          0.58431375, 0.5882353 , 0.5921569 , 0.59607846, 0.6       ,
                          0.6039216 , 0.60784316, 0.6117647 , 0.6156863 , 0.61960787,
                          0.62352943, 0.627451  , 0.6313726 , 0.63529414, 0.6392157 ,
                          0.6431373 , 0.64705884, 0.6509804 , 0.654902  , 0.65882355,
                          0.6627451 , 0.6666667 , 0.67058825, 0.6745098 , 0.6784314 ,
                          0.68235296, 0.6862745 , 0.6901961 , 0.69411767, 0.69803923,
                          0.7019608 , 0.7058824 , 0.70980394, 0.7137255 , 0.7176471 ,
                          0.72156864, 0.7254902 , 0.7294118 , 0.73333335, 0.7411765 ,
                          0.74509805, 0.7490196 , 0.7529412 , 0.75686276, 0.7647059 ,
                          0.76862746, 0.77254903, 0.7764706 , 0.78431374, 0.7882353 ,
                          0.7921569 , 0.79607844, 0.8       , 0.8039216 , 0.8156863 ,
                          0.81960785, 0.8235294 , 0.827451  , 0.83137256, 0.8392157 ,
                          0.8509804 , 0.85882354, 0.8627451 , 0.8666667 , 0.87058824,
                          0.8784314 , 0.88235295, 0.8901961 , 0.89411765, 0.90588236,
                          0.9098039 , 0.9137255 , 0.92156863, 0.92941177, 0.93333334,
                          0.9411765 , 0.9490196 , 0.9529412 , 0.972549  ], dtype=float32)
ic| C: 3
ic| H: 32
ic| PH: 4
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.
  warnings.warn(
ic| poss_augs: [[],
                [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=9, num_magnitude_bins=31)],
                [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=5, num_magnitude_bins=31)],
                [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=1, num_magnitude_bins=31)],
                [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=31)],
                [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=15)],
                [AugMix(interpolation=InterpolationMode.BILINEAR, severity=3, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True)],
                [AugMix(interpolation=InterpolationMode.BILINEAR, severity=1, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True)],
                [RandomHorizontalFlip(p=0.5), RandomVerticalFlip(p=0.5)],
                [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5)],
                [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False)],
                [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                 RandomCrop(size=(32, 32), padding=[4, 4, 4, 4], pad_if_needed=False, fill=0, padding_mode=constant)],
                [RandomCrop(size=(32, 32), padding=[4, 4, 4, 4], pad_if_needed=False, fill=0, padding_mode=constant)],
                [RandomCrop(size=(32, 32), padding=[4, 4, 4, 4], pad_if_needed=False, fill=0, padding_mode=constant),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5)],
                [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                 RandomCrop(size=(32, 32), padding=[4, 4, 4, 4], pad_if_needed=False, fill=0, padding_mode=constant),
                 RandomHorizontalFlip(p=0.5)],
                [<data_processor.RandomPixelChange object at 0x7f1300c17280>, ToTensor()],
                [<data_processor.RandomPixelChange object at 0x7f1300c15b10>, ToTensor()],
                [<data_processor.RandomPixelChange object at 0x7f1300c17250>, ToTensor()],
                [<data_processor.RandomPixelChange object at 0x7f1300c15de0>,
                 ToTensor(),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5)],
                [<data_processor.RandomPixelChange object at 0x7f1241fb7010>,
                 ToTensor(),
                 RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False)],
                [<data_processor.RandomPixelChange object at 0x7f1301638eb0>,
                 ToTensor(),
                 RandomCrop(size=(32, 32), padding=[4, 4, 4, 4], pad_if_needed=False, fill=0, padding_mode=constant)],
                [<data_processor.RandomPixelChange object at 0x7f1301638ca0>,
                 ToTensor(),
                 RandomHorizontalFlip(p=0.5),
                 RandomVerticalFlip(p=0.5),
                 RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False)]]
ic| individuals: ['asparagus_cicada',
                  'bold_myna',
                  'amigurumi_ocelot',
                  'greedy_nyala',
                  'invaluable_sawfly',
                  'jade_prawn',
                  'unyielding_donkey',
                  'classy_shellfish',
                  'tested_gaur',
                  'crafty_pogona',
                  'tourmaline_armadillo',
                  'shapeless_dragon',
                  'brainy_serval',
                  'innocent_parrot',
                  'jasmine_ringtail',
                  'augmented_mantis',
                  'graceful_kakapo',
                  'outrageous_smilodon',
                  'cerulean_bird',
                  'brainy_slug']
ic| params: [48.0, 48, 2.4999999999999982, 17, 8]
ic| params: [56.0, 80, 2.249999999999999, 12, 8]
ic| params: [64.0, 112, 2.6499999999999977, 12, 8]
ic| params: [56.0, 120, 2.799999999999997, 9, 8]
ic| params: [16.0, 88, 2.799999999999997, 21, 8]
ic| params: [40.0, 64, 2.1999999999999993, 17, 8]
ic| params: [40.0, 120, 2.4999999999999982, 13, 8]
ic| params: [40.0, 40, 2.1499999999999995, 18, 8]
ic| params: [64.0, 104, 2.1999999999999993, 12, 8]
ic| params: [48.0, 80, 2.599999999999998, 12, 8]
ic| params: [56.0, 96, 2.549999999999998, 21, 8]
ic| params: [16.0, 88, 2.05, 10, 8]
ic| params: [56.0, 112, 2.1999999999999993, 11, 8]
ic| params: [48.0, 112, 2.1499999999999995, 10, 8]
ic| params: [40.0, 64, 2.1999999999999993, 21, 8]
ic| params: [64.0, 64, 2.3999999999999986, 9, 8]
ic| params: [56.0, 80, 2.899999999999997, 19, 8]
ic| params: [40.0, 48, 2.1499999999999995, 19, 8]
ic| params: [48.0, 96, 2.249999999999999, 10, 8]
ic| params: [56.0, 72, 2.4499999999999984, 14, 8]
ic| individuals: ['asparagus_cicada',
                  'bold_myna',
                  'amigurumi_ocelot',
                  'greedy_nyala',
                  'invaluable_sawfly',
                  'jade_prawn',
                  'unyielding_donkey',
                  'classy_shellfish',
                  'tested_gaur',
                  'crafty_pogona',
                  'tourmaline_armadillo',
                  'shapeless_dragon',
                  'brainy_serval',
                  'innocent_parrot',
                  'jasmine_ringtail',
                  'augmented_mantis',
                  'graceful_kakapo',
                  'outrageous_smilodon',
                  'cerulean_bird',
                  'brainy_slug']
ic| params_dict: {'amigurumi_ocelot': [64.0, 112, 2.6499999999999977, 12, 8],
                  'asparagus_cicada': [48.0, 48, 2.4999999999999982, 17, 8],
                  'augmented_mantis': [64.0, 64, 2.3999999999999986, 9, 8],
                  'bold_myna': [56.0, 80, 2.249999999999999, 12, 8],
                  'brainy_serval': [56.0, 112, 2.1999999999999993, 11, 8],
                  'brainy_slug': [56.0, 72, 2.4499999999999984, 14, 8],
                  'cerulean_bird': [48.0, 96, 2.249999999999999, 10, 8],
                  'classy_shellfish': [40.0, 40, 2.1499999999999995, 18, 8],
                  'crafty_pogona': [48.0, 80, 2.599999999999998, 12, 8],
                  'graceful_kakapo': [56.0, 80, 2.899999999999997, 19, 8],
                  'greedy_nyala': [56.0, 120, 2.799999999999997, 9, 8],
                  'innocent_parrot': [48.0, 112, 2.1499999999999995, 10, 8],
                  'invaluable_sawfly': [16.0, 88, 2.799999999999997, 21, 8],
                  'jade_prawn': [40.0, 64, 2.1999999999999993, 17, 8],
                  'jasmine_ringtail': [40.0, 64, 2.1999999999999993, 21, 8],
                  'outrageous_smilodon': [40.0, 48, 2.1499999999999995, 19, 8],
                  'shapeless_dragon': [16.0, 88, 2.05, 10, 8],
                  'tested_gaur': [64.0, 104, 2.1999999999999993, 12, 8],
                  'tourmaline_armadillo': [56.0, 96, 2.549999999999998, 21, 8],
                  'unyielding_donkey': [40.0, 120, 2.4999999999999982, 13, 8]}
ic| '#############'
ic| aug: 0
ic| train_loader.dataset.transform.transforms: [Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 1
ic| train_loader.dataset.transform.transforms: [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=9, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 2
ic| train_loader.dataset.transform.transforms: [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=5, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 3
ic| train_loader.dataset.transform.transforms: [RandAugment(interpolation=InterpolationMode.NEAREST, num_ops=2, magnitude=1, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 4
ic| train_loader.dataset.transform.transforms: [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=31),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 5
ic| train_loader.dataset.transform.transforms: [TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, num_magnitude_bins=15),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 6
ic| train_loader.dataset.transform.transforms: [AugMix(interpolation=InterpolationMode.BILINEAR, severity=3, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 7
ic| train_loader.dataset.transform.transforms: [AugMix(interpolation=InterpolationMode.BILINEAR, severity=1, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 8
ic| train_loader.dataset.transform.transforms: [RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 9
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 10
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 11
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                RandomCrop(size=(32, 32), padding=[4, 4, 4, 4], pad_if_needed=False, fill=0, padding_mode=constant),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 12
ic| train_loader.dataset.transform.transforms: [RandomCrop(size=(32, 32), padding=[4, 4, 4, 4], pad_if_needed=False, fill=0, padding_mode=constant),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 13
ic| train_loader.dataset.transform.transforms: [RandomCrop(size=(32, 32), padding=[4, 4, 4, 4], pad_if_needed=False, fill=0, padding_mode=constant),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 14
ic| train_loader.dataset.transform.transforms: [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                RandomCrop(size=(32, 32), padding=[4, 4, 4, 4], pad_if_needed=False, fill=0, padding_mode=constant),
                                                RandomHorizontalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 15
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1300c17280>,
                                                ToTensor(),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 16
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1300c15b10>,
                                                ToTensor(),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 17
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1300c17250>,
                                                ToTensor(),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 18
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1300c15de0>,
                                                ToTensor(),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 19
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1241fb7010>,
                                                ToTensor(),
                                                RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 20
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1301638eb0>,
                                                ToTensor(),
                                                RandomCrop(size=(32, 32), padding=[4, 4, 4, 4], pad_if_needed=False, fill=0, padding_mode=constant),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
ic| '#############'
ic| aug: 21
ic| train_loader.dataset.transform.transforms: [<data_processor.RandomPixelChange object at 0x7f1301638ca0>,
                                                ToTensor(),
                                                RandomHorizontalFlip(p=0.5),
                                                RandomVerticalFlip(p=0.5),
                                                RandomErasing(p=0.2, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False),
                                                Normalize(mean=tensor([0.4914, 0.4823, 0.4466]), std=tensor([0.2468, 0.2431, 0.2613]))]
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:608: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["jacob_cov"] = scaler.fit_transform(subset_df_no_outliers[["jacob_cov"]])
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/data_processor.py:608: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  subset_df_no_outliers["jacob_cov"] = scaler.fit_transform(subset_df_no_outliers[["jacob_cov"]])
ic| f"best_augmentation: {best_aug}": 'best_augmentation: 4'
ic| f"selected transform {train_transform}": ('selected transform '
                                              '[TrivialAugmentWide(interpolation=InterpolationMode.NEAREST, '
                                              'num_magnitude_bins=31)]')
ic| self.x.shape: torch.Size([40000, 3, 32, 32])
ic| self.x.shape: torch.Size([10000, 3, 32, 32])
ic| self.x.shape: torch.Size([10000, 3, 32, 32])
ic| mode: 'T0'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 41429368832
ic| self.total_generations: 3
ic| 'Time remaining:'
ic| metadata['time_remaining']: 98423.91004443169
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 10, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 3, 'STEM_W': 32, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SGDRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                 score
                           super_yak  165.416409
ic| best_models.keys(): dict_keys(['super_yak'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 90.65,
               'codename': 'CIFAR10',
               'input_shape': [50000, 3, 32, 32],
               'mode': 'NAS',
               'num_classes': 10,
               'test_type': 'T0_Proxy/seed_3',
               'time_remaining': 98408.44369482994,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
Mode: T0
===========================================================================
=============    Your Unseen Data 2024 Submission is running     =============
===========================================================================
========== Dataset    in16    =============================================
  Metadata:
   - input_shape         : [148700, 3, 16, 16]
   - codename            : in16
   - benchmark           : 46.38
   - num_classes         : 120
   - time_remaining      : 107999.49123620987

=== Processing Data ===
  Allotted compute time remaining: ~29h,59m,59s

=== Performing NAS ===
  Allotted compute time remaining: ~29h,50m,20s
None

=== Training ===
  Allotted compute time remaining: ~29h,50m,1s
Early stopping at epoch 53
[31m[EVAL] Best accuracy:35.56666564941406[0m

=== Predicting ===
  Allotted compute time remaining: ~28h,56m,3s

========== Dataset   Volga    =============================================
  Metadata:
   - input_shape         : [50000, 20, 20, 20]
   - codename            : Volga
   - benchmark           : 71.35
   - num_classes         : 7
   - time_remaining      : 104158.90929675102

=== Processing Data ===
  Allotted compute time remaining: ~28h,55m,58s

=== Performing NAS ===
  Allotted compute time remaining: ~28h,49m,14s
spawn

=== Training ===
  Allotted compute time remaining: ~28h,49m,1s
Early stopping at epoch 100
[31m[EVAL] Best accuracy:83.45999908447266[0m

=== Predicting ===
  Allotted compute time remaining: ~28h,14m,32s

========== Dataset   Sokoto   =============================================
  Metadata:
   - input_shape         : [50000, 1, 9, 9]
   - codename            : Sokoto
   - benchmark           : 0.0
   - num_classes         : 9
   - time_remaining      : 101671.32470226288

=== Processing Data ===
  Allotted compute time remaining: ~28h,14m,31s

=== Performing NAS ===
  Allotted compute time remaining: ~28h,5m,11s
spawn

=== Training ===
  Allotted compute time remaining: ~28h,4m,54s
Early stopping at epoch 77
[31m[EVAL] Best accuracy:56.46999740600586[0m

=== Predicting ===
  Allotted compute time remaining: ~27h,31m,4s

========== Dataset  CIFAR10   =============================================
  Metadata:
   - input_shape         : [50000, 3, 32, 32]
   - codename            : CIFAR10
   - benchmark           : 90.65
   - num_classes         : 10
   - time_remaining      : 99062.68574404716

=== Processing Data ===
  Allotted compute time remaining: ~27h,31m,2s

=== Performing NAS ===
  Allotted compute time remaining: ~27h,20m,23s
spawn

=== Training ===
  Allotted compute time remaining: ~27h,20m,8s
Early stopping at epoch 97
[31m[EVAL] Best accuracy:92.50999450683594[0m

=== Predicting ===
  Allotted compute time remaining: ~26h,45m,49s

rm -Rf /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0/labels
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0/predictions
rsync -avr --exclude='**/*x.npy' --exclude='**/train*.npy' --exclude='**/valid*.npy'   --include='**/test_y.npy' datasets/* /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0/labels/
sending incremental file list
CIFAR10/
CIFAR10/cifar-10-python.tar.gz
CIFAR10/metadata
CIFAR10/test_y.npy
ImageNet16-120/
ImageNet16-120/metadata
ImageNet16-120/test_y.npy
Sudoku/
Sudoku/Example Image with Corresponding Sudoku Grid.png
Sudoku/README
Sudoku/metadata
Sudoku/test_y.npy
Sudoku/Sokoto/
Sudoku/Sokoto/augmentation_results.json
Sudoku/Sokoto/aug_0/
Sudoku/Sokoto/aug_0/student_best
Sudoku/Sokoto/aug_0/worklog.txt
Sudoku/Sokoto/aug_0/.ipynb_checkpoints/
Sudoku/Sokoto/aug_0/.ipynb_checkpoints/worklog-checkpoint.txt
Sudoku/Sokoto/aug_1/
Sudoku/Sokoto/aug_1/student_best
Sudoku/Sokoto/aug_1/worklog.txt
Sudoku/Sokoto/aug_1/.ipynb_checkpoints/
Sudoku/Sokoto/aug_1/.ipynb_checkpoints/worklog-checkpoint.txt
Sudoku/Sokoto/aug_2/
Sudoku/Sokoto/aug_2/student_best
Sudoku/Sokoto/aug_2/worklog.txt
Sudoku/Sokoto/aug_2/.ipynb_checkpoints/
Sudoku/Sokoto/aug_2/.ipynb_checkpoints/worklog-checkpoint.txt
Sudoku/Sokoto/aug_3/
Sudoku/Sokoto/aug_3/student_best
Sudoku/Sokoto/aug_3/worklog.txt
Sudoku/Sokoto/aug_3/.ipynb_checkpoints/
Sudoku/Sokoto/aug_3/.ipynb_checkpoints/worklog-checkpoint.txt
Sudoku/Sokoto/aug_4/
Sudoku/Sokoto/aug_4/student_best
Sudoku/Sokoto/aug_4/worklog.txt
Sudoku/Sokoto/aug_5/
Sudoku/Sokoto/aug_5/student_best
Sudoku/Sokoto/aug_5/worklog.txt
Sudoku/Sokoto/aug_5/.ipynb_checkpoints/
Sudoku/Sokoto/aug_5/.ipynb_checkpoints/worklog-checkpoint.txt
Sudoku/Sokoto/aug_6/
Sudoku/Sokoto/aug_6/student_best
Sudoku/Sokoto/aug_6/worklog.txt
Sudoku/Sokoto/aug_6/.ipynb_checkpoints/
Sudoku/Sokoto/aug_6/.ipynb_checkpoints/worklog-checkpoint.txt
Sudoku/Sokoto/aug_7/
Sudoku/Sokoto/aug_7/student_best
Sudoku/Sokoto/aug_7/worklog.txt
Sudoku/Sokoto/aug_8/
Sudoku/Sokoto/aug_8/student_best
Sudoku/Sokoto/aug_8/worklog.txt
Sudoku/Sokoto/aug_8/.ipynb_checkpoints/
Sudoku/Sokoto/aug_8/.ipynb_checkpoints/worklog-checkpoint.txt
Sudoku/Sokoto/aug_9/
Sudoku/Sokoto/aug_9/student_best
Sudoku/Sokoto/aug_9/worklog.txt
Sudoku/Sokoto/aug_9/.ipynb_checkpoints/
Sudoku/Sokoto/aug_9/.ipynb_checkpoints/worklog-checkpoint.txt
Voxel/
Voxel/Rendered Examples.png
Voxel/metadata
Voxel/test_y.npy

sent 620,487,017 bytes  received 951 bytes  137,886,215.11 bytes/sec
total size is 620,331,646  speedup is 1.00
cp -R /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/predictions /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0
cp evaluation/score.py /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0/score.py
cd /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0; python3 score.py
===========================================================================
=============    Your Unseen Data 2024 Submission is scoring     =============
===========================================================================
== Scoring Voxel ==
Raw Score:    83.810
Adj Score:    4.349
Model Params: 1,494,266
Runtime:      2,487.5s
== Scoring ImageNet16-120 ==
Raw Score:    35.233
Adj Score:    -2.079
Model Params: 1,709,760
Runtime:      3,836.5s
== Scoring Sudoku ==
Raw Score:    57.350
Adj Score:    5.735
Model Params: 2,632,130
Runtime:      2,607.7s
== Scoring CIFAR10 ==
Raw Score:    92.130
Adj Score:    1.583
Model Params: 3,655,086
Runtime:      2,714.9s
===========================
Final Score: 9.588
=== JOB_STATISTICS ===
=== current date     : Wed 23 Oct 2024 10:38:38 AM CEST
= Job-ID             : 916707 on tinygpu
= Job-Name           : /home/woody/iwb3/iwb3021h/THESIS_RESULTS/hpcruns/evonas
= Job-Command        : /home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/evonas_job_full_main_0.sh
= Initial workdir    : /home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024
= Queue/Partition    : a100
= Slurm account      : iwb3 with QOS=normal
= Requested resources:  for 23:59:00
= Elapsed runtime    : 03:16:35
= Total RAM usage    : 5.7 GiB of requested  GiB (%)   
= Node list          : tg092
= Subm/Elig/Start/End: 2024-10-22T20:43:36 / 2024-10-22T20:43:36 / 2024-10-23T07:22:03 / 2024-10-23T10:38:38
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc          102.9G   104.9G   209.7G        N/A     196K     500K   1,000K        N/A    
    /home/vault        984.8G  1048.6G  2097.2G        N/A     180K     200K     400K        N/A    
    /home/woody        866.7G  1000.0G  1500.0G        N/A     259K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:C1:00.0, 431655, 22 %, 5 %, 9148 MiB, 11658543 ms
