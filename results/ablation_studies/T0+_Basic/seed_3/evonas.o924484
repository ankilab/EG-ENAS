### Starting TaskPrologue of job 924484 on tg096 at Fri 01 Nov 2024 01:57:08 PM CET
Running on cores 64-95 with governor ondemand
Fri Nov  1 13:57:08 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:81:00.0 Off |                    0 |
| N/A   35C    P0             55W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

Loading python/pytorch-1.13py3.10
  Loading requirement: cuda/11.6.1
rm -Rf /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0
rm -Rf /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0
rm -Rf /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/predictions
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/datasets
rsync -ar --exclude='**/test_y.npy' datasets/* /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/datasets/
cp -R evaluation/main.py /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/main.py
cp -R anki_lab_submission/* /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0
cd /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0; python3 main.py --mode T0 --select_augment Basic
ic| self.select_augment: 'Basic'
ic| f"selected transform {train_transform}": ('selected transform [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, '
                                              '3.3), value=[0.0], inplace=False), RandomCrop(size=(24, 24), padding=[3, 3, '
                                              '3, 3], pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([50000, 1, 24, 24])
ic| self.x.shape: torch.Size([10000, 1, 24, 24])
ic| self.x.shape: torch.Size([10000, 1, 24, 24])
ic| mode: 'T0'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 42404610048
ic| self.total_generations: 3
ic| 'Time remaining:'
ic| metadata['time_remaining']: 107998.91276741028
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 10, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 1, 'STEM_W': 24, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                    score
                           tangible_bull  94.137687
ic| best_models.keys(): dict_keys(['tangible_bull'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 85.2,
               'codename': 'LaMelo',
               'input_shape': [50000, 1, 24, 24],
               'mode': 'NAS',
               'num_classes': 10,
               'test_type': 'T0_Basic/seed_3',
               'time_remaining': 107898.52832078934,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Basic'
ic| f"selected transform {train_transform}": ('selected transform [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, '
                                              '3.3), value=[0.0], inplace=False), RandomCrop(size=(27, 18), padding=[3, 3, '
                                              '2, 2], pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([45000, 1, 27, 18])
ic| self.x.shape: torch.Size([15000, 1, 27, 18])
ic| self.x.shape: torch.Size([6000, 1, 27, 18])
ic| mode: 'T0'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 8388739072
ic| self.total_generations: 1
ic| 'Time remaining:'
ic| metadata['time_remaining']: 105652.75233507156
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 6, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 1, 'STEM_W': 18, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                            score
                           fluorescent_alligator  87.495896
ic| best_models.keys(): dict_keys(['fluorescent_alligator'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 40.98,
               'codename': 'Gutenberg',
               'input_shape': [45000, 1, 27, 18],
               'mode': 'NAS',
               'num_classes': 6,
               'test_type': 'T0_Basic/seed_3',
               'time_remaining': 105571.03650331497,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Basic'
ic| f"selected transform {train_transform}": ('selected transform [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, '
                                              '3.3), value=[0.0], inplace=False), RandomCrop(size=(28, 28), padding=[3, 3, '
                                              '3, 3], pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([45000, 3, 28, 28])
ic| self.x.shape: torch.Size([15000, 3, 28, 28])
ic| self.x.shape: torch.Size([10000, 3, 28, 28])
ic| mode: 'T0'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 7447117824
ic| self.total_generations: 1
ic| 'Time remaining:'
ic| metadata['time_remaining']: 103302.07691311836
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 20, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 3, 'STEM_W': 28, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                      score
                           burrowing_viper  94.798977
ic| best_models.keys(): dict_keys(['burrowing_viper'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 89.85,
               'codename': 'Adaline',
               'input_shape': [50000, 3, 28, 28],
               'mode': 'NAS',
               'num_classes': 20,
               'test_type': 'T0_Basic/seed_3',
               'time_remaining': 103219.0998723507,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Basic'
ic| f"selected transform {train_transform}": ('selected transform [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, '
                                              '3.3), value=[0.0], inplace=False), RandomCrop(size=(8, 8), padding=[1, 1, 1, '
                                              '1], pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([49998, 12, 8, 8])
ic| self.x.shape: torch.Size([9999, 12, 8, 8])
ic| self.x.shape: torch.Size([9999, 12, 8, 8])
ic| mode: 'T0'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 7015104512
ic| self.total_generations: 1
ic| 'Time remaining:'
ic| metadata['time_remaining']: 100800.05763840675
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 3, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 12, 'STEM_W': 8, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                  score
                           bulky_camel  97.009963
ic| best_models.keys(): dict_keys(['bulky_camel'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 57.826,
               'codename': 'Chester',
               'input_shape': [49998, 12, 8, 8],
               'mode': 'NAS',
               'num_classes': 3,
               'test_type': 'T0_Basic/seed_3',
               'time_remaining': 100712.12081694603,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Basic'
ic| f"selected transform {train_transform}": ('selected transform [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, '
                                              '3.3), value=[0.0], inplace=False), RandomCrop(size=(64, 64), padding=[8, 8, '
                                              '8, 8], pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([43821, 3, 60, 60])
ic| self.x.shape: torch.Size([8785, 3, 60, 60])
ic| self.x.shape: torch.Size([8751, 3, 60, 60])
ic| mode: 'T0'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 5473697792
ic| self.total_generations: 1
ic| 'Time remaining:'
ic| metadata['time_remaining']: 100040.25494408607
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 10, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 3, 'STEM_W': 64, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                      score
                           flashy_stingray  82.862216
ic| best_models.keys(): dict_keys(['flashy_stingray'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 80.33,
               'codename': 'Sadie',
               'input_shape': [50000, 3, 64, 64],
               'mode': 'NAS',
               'num_classes': 10,
               'test_type': 'T0_Basic/seed_3',
               'time_remaining': 99955.49718570709,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Basic'
ic| f"selected transform {train_transform}": ('selected transform [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, '
                                              '3.3), value=[0.0], inplace=False), RandomCrop(size=(28, 28), padding=[3, 3, '
                                              '3, 3], pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([50000, 3, 28, 28])
ic| self.x.shape: torch.Size([10000, 3, 28, 28])
ic| self.x.shape: torch.Size([10000, 3, 28, 28])
ic| mode: 'T0'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 19560267776
ic| self.total_generations: 3
ic| 'Time remaining:'
ic| metadata['time_remaining']: 93725.61713600159
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 10, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 3, 'STEM_W': 28, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                     score
                           impartial_asp  101.201292
ic| best_models.keys(): dict_keys(['impartial_asp'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 90.87,
               'codename': 'Mateo',
               'input_shape': [50000, 3, 28, 28],
               'mode': 'NAS',
               'num_classes': 10,
               'test_type': 'T0_Basic/seed_3',
               'time_remaining': 93631.76462841034,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
ic| self.select_augment: 'Basic'
ic| f"selected transform {train_transform}": ('selected transform [RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, '
                                              '3.3), value=[0.0], inplace=False), RandomCrop(size=(64, 64), padding=[8, 8, '
                                              '8, 8], pad_if_needed=False, fill=0, padding_mode=constant), '
                                              'RandomHorizontalFlip(p=0.5)]')
ic| self.x.shape: torch.Size([45000, 3, 64, 64])
ic| self.x.shape: torch.Size([15000, 3, 64, 64])
ic| self.x.shape: torch.Size([10000, 3, 64, 64])
ic| mode: 'T0'
ic| f"Mode {mode}": 'Mode T0'
ic| get_gpu_memory(0): 7629570048
ic| self.total_generations: 1
ic| 'Time remaining:'
ic| metadata['time_remaining']: 90940.8174688816
ic| self.zcost_nas: True
ic| self.cfg: CfgNode({'MODEL': CfgNode({'TYPE': 'regnet', 'NUM_CLASSES': 4, 'ACTIVATION_FUN': 'relu', 'ACTIVATION_INPLACE': True, 'SCALING_TYPE': '', 'SCALING_FACTOR': 1.0}), 'REGNET': CfgNode({'STEM_TYPE': 'res_stem_cifar', 'INPUT_CHANNELS': 3, 'STEM_W': 64, 'BLOCK_TYPE': 'res_bottleneck_block', 'STRIDE': 2, 'SE_ON': True, 'SE_R': 0.25, 'DEPTH': 20, 'W0': 232, 'WA': 115.89, 'WM': 2.53, 'GROUP_W': 8, 'BOT_MUL': 1.0, 'HEAD_W': 0, 'DOWNSAMPLE': 'avg', 'DROP_RATE': 0.01, 'DROPOUT': 0.2}), 'BN': CfgNode({'EPS': 1e-05, 'MOM': 0.1, 'ZERO_INIT_FINAL_GAMMA': False}), 'LN': CfgNode({'EPS': 1e-05}), 'DESC': ''})
ic| samples: 120
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/.testvenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/search_space/RegNet.py:299: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  ranking_test_df[pred_column]=sgd_regressor.predict(X_test)
ic| ranking_prediction_df:                    score
                           indigo_weasel  83.700257
ic| best_models.keys(): dict_keys(['indigo_weasel'])
ic| self.initial_population_size: 120
ic| metadata: {'benchmark': 47.008,
               'codename': 'Caitie',
               'input_shape': [49260, 3, 64, 64],
               'mode': 'NAS',
               'num_classes': 4,
               'test_type': 'T0_Basic/seed_3',
               'time_remaining': 90864.60420846939,
               'train_config_path': 'configs/train/finetuning_generation_adam.yaml'}
ic| cfg_path: 'configs/train/finetuning_generation_adam.yaml'
ic| self.cfg.SOLVER.LR: 0.001
ic| self.cfg.SOLVER.EPOCHS-self.cfg.SOLVER.SWA_START: 10
ic| self.cfg.SOLVER.EPOCHS: 100
/home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/trainer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=device)
Mode: T0
===========================================================================
=============    Your Unseen Data 2024 Submission is running     =============
===========================================================================
========== Dataset   LaMelo   =============================================
  Metadata:
   - num_classes         : 10
   - codename            : LaMelo
   - input_shape         : [50000, 1, 24, 24]
   - benchmark           : 85.2
   - time_remaining      : 107999.8051173687

=== Processing Data ===
  Allotted compute time remaining: ~29h,59m,59s

=== Performing NAS ===
  Allotted compute time remaining: ~29h,59m,58s
None

=== Training ===
  Allotted compute time remaining: ~29h,58m,18s
Early stopping at epoch 61
[31m[EVAL] Best accuracy:78.80999755859375[0m

=== Predicting ===
  Allotted compute time remaining: ~29h,20m,56s

========== Dataset Gutenberg  =============================================
  Metadata:
   - input_shape         : [45000, 1, 27, 18]
   - codename            : Gutenberg
   - benchmark           : 40.98
   - num_classes         : 6
   - time_remaining      : 105652.83489608765

=== Processing Data ===
  Allotted compute time remaining: ~29h,20m,52s

=== Performing NAS ===
  Allotted compute time remaining: ~29h,20m,52s
spawn

=== Training ===
  Allotted compute time remaining: ~29h,19m,31s
Early stopping at epoch 59
[31m[EVAL] Best accuracy:46.0533332824707[0m

=== Predicting ===
  Allotted compute time remaining: ~28h,41m,45s

========== Dataset  Adaline   =============================================
  Metadata:
   - num_classes         : 20
   - input_shape         : [50000, 3, 28, 28]
   - codename            : Adaline
   - benchmark           : 89.85
   - time_remaining      : 103302.72078847885

=== Processing Data ===
  Allotted compute time remaining: ~28h,41m,42s

=== Performing NAS ===
  Allotted compute time remaining: ~28h,41m,42s
spawn

=== Training ===
  Allotted compute time remaining: ~28h,40m,19s
[31m[EVAL] Best accuracy:96.0[0m

=== Predicting ===
  Allotted compute time remaining: ~28h,0m,2s

========== Dataset  Chester   =============================================
  Metadata:
   - input_shape         : [49998, 12, 8, 8]
   - codename            : Chester
   - benchmark           : 57.826
   - num_classes         : 3
   - time_remaining      : 100800.20717954636

=== Processing Data ===
  Allotted compute time remaining: ~28h,0m,0s

=== Performing NAS ===
  Allotted compute time remaining: ~28h,0m,0s
spawn

=== Training ===
  Allotted compute time remaining: ~27h,58m,32s
Early stopping at epoch 23
[31m[EVAL] Best accuracy:53.13531494140625[0m

=== Predicting ===
  Allotted compute time remaining: ~27h,47m,30s

========== Dataset   Sadie    =============================================
  Metadata:
   - input_shape         : [50000, 3, 64, 64]
   - codename            : Sadie
   - benchmark           : 80.33
   - num_classes         : 10
   - time_remaining      : 100044.49060845375

=== Processing Data ===
  Allotted compute time remaining: ~27h,47m,24s

=== Performing NAS ===
  Allotted compute time remaining: ~27h,47m,20s
spawn

=== Training ===
  Allotted compute time remaining: ~27h,45m,55s
[31m[EVAL] Best accuracy:96.8469009399414[0m

=== Predicting ===
  Allotted compute time remaining: ~26h,2m,10s

========== Dataset   Mateo    =============================================
  Metadata:
   - num_classes         : 10
   - input_shape         : [50000, 3, 28, 28]
   - codename            : Mateo
   - benchmark           : 90.87
   - time_remaining      : 93726.30934882164

=== Processing Data ===
  Allotted compute time remaining: ~26h,2m,6s

=== Performing NAS ===
  Allotted compute time remaining: ~26h,2m,5s
spawn

=== Training ===
  Allotted compute time remaining: ~26h,0m,31s
[31m[EVAL] Best accuracy:98.29000091552734[0m

=== Predicting ===
  Allotted compute time remaining: ~25h,15m,51s

========== Dataset   Caitie   =============================================
  Metadata:
   - num_classes         : 4
   - input_shape         : [49260, 3, 64, 64]
   - codename            : Caitie
   - benchmark           : 47.008
   - time_remaining      : 90945.70195817947

=== Processing Data ===
  Allotted compute time remaining: ~25h,15m,45s

=== Performing NAS ===
  Allotted compute time remaining: ~25h,15m,40s
spawn

=== Training ===
  Allotted compute time remaining: ~25h,14m,24s
[31m[EVAL] Best accuracy:92.51333618164062[0m

=== Predicting ===
  Allotted compute time remaining: ~23h,10m,46s

rm -Rf /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0/labels
mkdir /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0/predictions
rsync -avr --exclude='**/*x.npy' --exclude='**/train*.npy' --exclude='**/valid*.npy'   --include='**/test_y.npy' datasets/* /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0/labels/
sending incremental file list
AddNIST/
AddNIST/README
AddNIST/metadata
AddNIST/test_y.npy
CIFARTile/
CIFARTile/README.txt
CIFARTile/metadata
CIFARTile/test_y.npy
Chesseract/
Chesseract/README
Chesseract/metadata
Chesseract/test_y.npy
GeoClassing/
GeoClassing/README GeoClassing Dataset.txt
GeoClassing/metadata
GeoClassing/test_y.npy
Gutenberg/
Gutenberg/metadata
Gutenberg/test_y.npy
Language/
Language/README
Language/metadata
Language/test_y.npy
MultNIST/
MultNIST/README
MultNIST/metadata
MultNIST/test_y.npy

sent 529,436 bytes  received 448 bytes  1,059,768.00 bytes/sec
total size is 527,679  speedup is 1.00
cp -R /home/woody/iwb3/iwb3021h/THESIS_RESULTS/package0/predictions /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0
cp evaluation/score.py /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0/score.py
cd /home/woody/iwb3/iwb3021h/THESIS_RESULTS/scoring0; python3 score.py
===========================================================================
=============    Your Unseen Data 2024 Submission is scoring     =============
===========================================================================
== Scoring Language ==
Raw Score:    79.970
Adj Score:    -3.534
Model Params: 68,205,898
Runtime:      2,346.7s
== Scoring Gutenberg ==
Raw Score:    47.600
Adj Score:    1.122
Model Params: 90,767,160
Runtime:      2,349.2s
== Scoring AddNIST ==
Raw Score:    96.760
Adj Score:    6.808
Model Params: 9,420,739
Runtime:      2,502.1s
== Scoring Chesseract ==
Raw Score:    49.515
Adj Score:    -1.971
Model Params: 93,646,275
Runtime:      752.4s
== Scoring GeoClassing ==
Raw Score:    96.949
Adj Score:    8.449
Model Params: 9,561,730
Runtime:      6,317.2s
== Scoring MultNIST ==
Raw Score:    95.930
Adj Score:    5.542
Model Params: 9,469,345
Runtime:      2,776.3s
== Scoring CIFARTile ==
Raw Score:    84.880
Adj Score:    7.147
Model Params: 13,470,516
Runtime:      7,504.3s
===========================
Final Score: 23.563
=== JOB_STATISTICS ===
=== current date     : Fri 01 Nov 2024 08:47:53 PM CET
= Job-ID             : 924484 on tinygpu
= Job-Name           : /home/woody/iwb3/iwb3021h/THESIS_RESULTS/hpcruns/evonas
= Job-Command        : /home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024/evonas_job_full_main_0.sh
= Initial workdir    : /home/hpc/iwb3/iwb3021h/NAS_CHALLENGE/NAS_Challenge_AutoML_2024
= Queue/Partition    : a100
= Slurm account      : iwb3 with QOS=normal
= Requested resources:  for 23:59:00
= Elapsed runtime    : 06:50:48
= Total RAM usage    : 8.5 GiB of requested  GiB (%)   
= Node list          : tg096
= Subm/Elig/Start/End: 2024-11-01T13:57:04 / 2024-11-01T13:57:04 / 2024-11-01T13:57:05 / 2024-11-01T20:47:53
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc          103.5G   104.9G   209.7G        N/A     198K     500K   1,000K        N/A    
    /home/woody        943.4G  1000.0G  1500.0G        N/A     262K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:81:00.0, 899221, 70 %, 49 %, 40368 MiB, 24562675 ms
